{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network\n",
    "\n",
    "Trying to solve a prediction problem using sci-kit learn Neural network models. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading \n",
    "\n",
    "Everything was already processed so, just using that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import explained_variance_score\n",
    "from sklearn.metrics import r2_score\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.pyplot as plt \n",
    "pd.options.display.float_format = '{:.2f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()\n",
    "#os.chdir('c:\\\\Users\\\\amcfa\\\\gitfiles\\\\Projects\\\\MastersWork\\\\shorter_ML_Projects\\\\Machine-Learning-_-Prediction')\n",
    "X1=pd.read_csv(os.getcwd()+ '/X1.csv')\n",
    "X2=pd.read_csv(os.getcwd()+ '/X2.csv')\n",
    "from sklearn.utils import shuffle\n",
    "X1 = shuffle(X1)\n",
    "X2=shuffle(X2)\n",
    "y_train=X1['Data_x'].reset_index(drop=True) # Separating all of the data\n",
    "y_test=X2['Data_x'].reset_index(drop=True)\n",
    "X_train1 = X1.iloc[:,3: ]\n",
    "X_test1 = X2.iloc[:,3: ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train1)\n",
    "X_train=scaler.transform(X_train1)\n",
    "X_test=scaler.transform(X_test1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A first Pass\n",
    "Just using the model as it comes. No parameter optimization here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = MLPRegressor(max_iter=500).fit(X_train, y_train)\n",
    "regr.predict(X_test)\n",
    "regr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = MLPRegressor().fit(X_train, y_train)\n",
    "y_pred=regr.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true=y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_trial1=pd.DataFrame(y_pred,y_true).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_trial1=pd.DataFrame(y_pred,y_true).reset_index()\n",
    "results_trial1=results_trial1.rename(columns={'Data_x':'true',0:'predicted'})\n",
    "results_trial1['how_off']= ((results_trial1['true']-results_trial1['predicted'])/results_trial1['true'])*100\n",
    "results_trial1.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r1 = np.arange(len(results_trial1['true']))\n",
    "\n",
    "plt.bar(r1, results_trial1['true'], color='#7f6d5f', edgecolor='white', label='true values')\n",
    "plt.scatter(r1, results_trial1['predicted'], color='#557f2d', edgecolor='white', label='predicted values')\n",
    "plt.xlabel('Run #')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.title('Predicted value vs true value')\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean absolute Error',mean_absolute_error(y_true, y_pred))\n",
    "print('Mean squared error', mean_squared_error(y_true, y_pred))\n",
    "print(('Explained variance score',explained_variance_score(y_true, y_pred)))\n",
    "print(('R_2 score',r2_score(y_true, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model needed some optimization for sure. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization\n",
    "\n",
    "\n",
    "### Selecting activation function\n",
    "\n",
    "Default activation is `relu` \\\n",
    "references*\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPRegressor.html#sklearn.neural_network.MLPRegressor\n",
    "\n",
    "Will try:\\\n",
    "`identity`-no-op activation, useful to implement linear bottleneck, returns f(x) = x\\\n",
    "`logistic`-The logistic sigmoid function, returns f(x) = 1 / (1 + exp(-x)).\\\n",
    "`tahn`-the hyperbolic tan function, returns f(x) = tanh(x)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m=['relu','identity','logistic','tanh']\n",
    "abc=[]\n",
    "for i,j in (enumerate(m)):\n",
    "    mod=j\n",
    "    regr=MLPRegressor(activation=j).fit(X_train, y_train)\n",
    "    regr.predict(X_test)\n",
    "    y_pred=regr.predict(X_test)\n",
    "    score=regr.score(X_test, y_test)\n",
    "    abc.append([mod,score,mean_absolute_error(y_true, y_pred),mean_squared_error(y_true, y_pred),\n",
    "                explained_variance_score(y_true, y_pred),r2_score(y_true, y_pred)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores=pd.DataFrame(abc,columns=['iter','score','MAE','MSE','EV','R2'])\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "looks like identity is the winner here. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m=2500\n",
    "abc=[]\n",
    "defg=[]\n",
    "#This needs to run 3 times and in those 3 times. Needs to give results\n",
    "for i in range(1,m,100):\n",
    "    regr=MLPRegressor(activation='identity',max_iter=i).fit(X_train, y_train)\n",
    "    regr.predict(X_test)\n",
    "    y_pred=regr.predict(X_test)\n",
    "    score=regr.score(X_test, y_test)\n",
    "    abc.append([i,score,mean_absolute_error(y_true, y_pred)\n",
    "                ,mean_squared_error(y_true, y_pred)\n",
    "                ,explained_variance_score(y_true, y_pred),r2_score(y_true, y_pred)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores=pd.DataFrame(abc,columns=['iter','score','MAE','MSE','EV','R2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(scores['MAE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(scores['MSE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(scores['EV'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best iterations is 2300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing the solver\n",
    "\n",
    "Going to change the solver now- the only alternative to adam is `lbfgs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m=['lbfgs']\n",
    "abc=[]\n",
    "for i,j in (enumerate(m)):\n",
    "    mod=j\n",
    "    regr=MLPRegressor(activation='identity',max_iter=2300,solver=j).fit(X_train, y_train)\n",
    "    regr.predict(X_test)\n",
    "    y_pred=regr.predict(X_test)\n",
    "    score=regr.score(X_test, y_test)\n",
    "    abc.append([mod,score,mean_absolute_error(y_true, y_pred),mean_squared_error(y_true, y_pred),\n",
    "                explained_variance_score(y_true, y_pred),r2_score(y_true, y_pred)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores=pd.DataFrame(abc,columns=['solver','score','MAE','MSE','EV','R2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_trial1=pd.DataFrame(y_pred,y_true).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_trial1=pd.DataFrame(y_pred,y_true).reset_index()\n",
    "results_trial1=results_trial1.rename(columns={'Data_x':'true',0:'predicted'})\n",
    "results_trial1['how_off']= ((results_trial1['true']-results_trial1['predicted'])/results_trial1['true'])*100\n",
    "results_trial1.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r1 = np.arange(len(results_trial1['true']))\n",
    "\n",
    "plt.bar(r1, results_trial1['true'], color='#7f6d5f', edgecolor='white', label='true values')\n",
    "plt.scatter(r1, results_trial1['predicted'], color='#557f2d', edgecolor='white', label='predicted values')\n",
    "plt.xlabel('Run #')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.title('Predicted value vs true value')\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import d2_absolute_error_score\n",
    "d2_absolute_error_score(y_true, y_pred,multioutput='raw_values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean absolute Error',mean_absolute_error(y_true, y_pred))\n",
    "print('Mean squared error', mean_squared_error(y_true, y_pred))\n",
    "print(('Explained variance score',explained_variance_score(y_true, y_pred)))\n",
    "print(('R_2 score',r2_score(y_true, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "\n",
    "The Neural Network Model performed very well. With a prediction accuracy of 100%.\\\n",
    "The `MAE` was 0.032168487841461764\\\n",
    "The `MSE` was 0.0030038938705200698\\\n",
    "The `Explained variance` was 0.9999999998453984\\\n",
    "The $ R^2 $ was 0.9999999998356973"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
